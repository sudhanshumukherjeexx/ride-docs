{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to RIDE \ud83d\ude80","text":"<p>No Code. No Hassle. Just Results. RIDE (Rapid Insights Data Engine) is a powerful no-code data science and machine learning platform designed to help users explore, clean, transform, analyze, and model datasets with the help of AI \u2014 all within an intuitive browser interface.</p>"},{"location":"#what-can-you-do-with-ride","title":"\ud83d\udd0d What Can You Do with RIDE?","text":"<ul> <li>Upload or select default datasets</li> <li>Automatically explore summary stats, correlations, and outliers</li> <li>Visualize data using 10+ interactive plot types</li> <li>Impute missing values with 5+ smart strategies</li> <li>Scale, transform, encode features easily</li> <li>Perform statistical hypothesis testing</li> <li>Run AutoML pipelines for classification, regression, and clustering</li> <li>Chat with your dataset using OpenAI and Hugging Face LLMs</li> </ul>"},{"location":"#walkthrough-video","title":"\ud83d\udcfa Walkthrough Video","text":"<p>Watch the full demo below to see RIDE in action:</p>"},{"location":"#built-by-sudhanshu-mukherjee","title":"\ud83d\udc68\u200d\ud83d\udcbb Built by Sudhanshu Mukherjee","text":"<p>\ud83d\udcbb GitHub   | \ud83d\udceb Email</p> <p>Enjoy exploring your data \u2728</p>"},{"location":"01_data_overview/","title":"01 \u2013 Data Overview","text":""},{"location":"01_data_overview/#ride-user-manual-panel-1-data-overview","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 1: Data Overview","text":""},{"location":"01_data_overview/#purpose-of-this-panel","title":"\ud83d\udd0d Purpose of this Panel","text":"<p>The Data Overview panel is designed to give users an instant, interactive understanding of their dataset. It provides descriptive statistics, data types, shape, missing value counts, and correlation analysis\u2014all wrapped with optional AI-driven explanations.</p> <p><code>Recommended Reading</code></p> <ul> <li>Blog: A Gentle Introduction to Python\u2019s Pandas Library \u2014 The First 5 Functions You Need to Know</li> </ul>"},{"location":"01_data_overview/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Add API Key (on Home Page)     The user needs to first input their OpenAI API key for GPT-powered insights to work.</p> </li> <li> <p>Upload Dataset     The dataset must be uploaded. The tool expects a tabular format (e.g., CSV, Excel).</p> </li> <li> <p>View Header &amp; Dataset Cards     A GIF and a visual introduction describe what this panel does.</p> </li> <li> <p>Explore Tabs:</p> <ul> <li> <p>\ud83d\udcca Basic Statistics</p> <ul> <li> <p>Preview of top rows of the dataset.</p> </li> <li> <p>Descriptive statistics using <code>.describe()</code>.</p> </li> <li> <p>Info about shape, features, data types, and missing values.</p> </li> <li> <p>Option to trigger AI analysis of summary statistics.</p> </li> </ul> </li> <li> <p>\ud83d\udd04 Correlations</p> <ul> <li> <p>Correlation matrix for numeric features.</p> </li> <li> <p>Plotly heatmap visualization.</p> </li> <li> <p>Optional GPT-based insights for both matrix and heatmap.</p> </li> </ul> </li> </ul> </li> </ol>"},{"location":"01_data_overview/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Dataset Preview Shows the first few rows of the uploaded dataset. Statistical Summary Displays count, mean, std, min, max, and quartiles for each numeric column. Shape and Columns Shows number of rows/columns and feature names. Data Types Indicates each column\u2019s datatype (int, float, object, etc.). Missing Values Count Identifies which columns have missing data and how much. Correlation Matrix Matrix showing linear relationships between numeric features. Correlation Heatmap Heatmap using Plotly to visualize strong/weak relationships. AI-Powered Insights GPT-generated explanations for summary stats and heatmap analysis."},{"location":"01_data_overview/#ai-features","title":"\ud83e\udd16 AI Features","text":"<ul> <li> <p>LLM (GPT-4o-mini) analyzes:</p> <ul> <li> <p>Statistical distribution</p> </li> <li> <p>Data trends</p> </li> <li> <p>Feature relationships</p> </li> </ul> </li> <li> <p>Image-based GPT analysis of the correlation heatmap using the <code>AnalyzeImage()</code> function.</p> </li> </ul>"},{"location":"01_data_overview/#recommended-reading","title":"<code>Recommended Reading</code>","text":"<ul> <li>Blog: A Gentle Introduction to Python\u2019s Pandas Library \u2014 The First 5 Functions You Need to Know</li> </ul>"},{"location":"02_data_cleanup_and_conversion/","title":"02 \u2013 Data Cleanup & Conversion","text":""},{"location":"02_data_cleanup_and_conversion/#ride-user-manual-panel-2-data-cleanup-and-conversion","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 2: Data Cleanup and Conversion","text":""},{"location":"02_data_cleanup_and_conversion/#purpose-of-the-panel","title":"\ud83d\udd04 Purpose of the Panel","text":"<p>This panel enables users to clean their dataset by:</p> <ul> <li> <p>Removing duplicate rows</p> </li> <li> <p>Converting feature columns to appropriate data types     These preprocessing steps are crucial for maintaining data quality and preparing datasets for deeper analysis or modeling.</p> </li> </ul> <p><code>Recommended Reading</code></p> <ul> <li>Blog: Handling Duplicate values</li> </ul>"},{"location":"02_data_cleanup_and_conversion/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset     Users first upload a dataset (handled globally in the app).</p> </li> <li> <p>View Panel Intro     A GIF and explanation help the user understand what this panel does.</p> </li> <li> <p>Use Two Tabs:</p> <ul> <li> <p>Handle Duplicates: Automatically detects and removes duplicates.</p> </li> <li> <p>Convert Data Types:</p> <ul> <li> <p>User selects a column and target data type (INT, FLOAT, BOOLEAN, STRING, DATETIME).</p> </li> <li> <p>The backend intelligently parses and casts the column.</p> </li> <li> <p>Before/after comparison of data types is shown for validation.</p> </li> </ul> </li> </ul> </li> </ol>"},{"location":"02_data_cleanup_and_conversion/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Duplicate Row Detection Identifies and displays the count of duplicated rows in the dataset. Remove Duplicates Button Allows users to remove duplicate rows in one click. Data Type Conversion Provides dropdowns for selecting a column and a target data type. Smart Parsing Logic Automatically handles tricky conversions like datetime or boolean strings. Type Comparison View Displays side-by-side comparison of original and updated data types."},{"location":"02_data_cleanup_and_conversion/#how-conversions-are-handled-internally","title":"\ud83e\udde0 How Conversions Are Handled Internally","text":"<ul> <li> <p>INT/FLOAT:</p> <ul> <li> <p>Strips non-numeric characters using regex.</p> </li> <li> <p>Converts strings only if not already numeric.</p> </li> </ul> </li> <li> <p>BOOLEAN:</p> <ul> <li>Converts \u201ctrue/yes/1/y\u201d strings to <code>True</code>, others to <code>False</code>.</li> </ul> </li> <li> <p>DATETIME:</p> <ul> <li> <p>Tries multiple common date formats.</p> </li> <li> <p>Uses <code>polars.str.to_datetime()</code> with fallback parsing.</p> </li> </ul> </li> </ul>"},{"location":"02_data_cleanup_and_conversion/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Blog: Handling Duplicate values</li> </ul>"},{"location":"03_exploratory_data_analysis/","title":"03 \u2013 Exploratory Data Analysis","text":""},{"location":"03_exploratory_data_analysis/#ride-user-manual-panel-3-exploratory-data-analysis-eda","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 3: Exploratory Data Analysis (EDA)","text":""},{"location":"03_exploratory_data_analysis/#purpose-of-the-panel","title":"\ud83d\udcca Purpose of the Panel","text":"<p>The EDA Panel helps users visualize patterns, distributions, and relationships in their data using a suite of 15+ interactive plot types. These visuals make it easier to understand underlying structures before performing modeling or transformation.</p> <p><code>Recommended Reading</code></p> <ul> <li>Blog: How to choose the right data visualization</li> <li>Blog: A Complete Guide to Python Data Visualization</li> <li>Blog: Types of Plots: Visualization from Concept to Code</li> </ul>"},{"location":"03_exploratory_data_analysis/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset &amp; Select Preprocessed Version     User selects from:</p> <ul> <li>Initial DataFrame</li> <li>After Missing Value Imputation</li> <li>After Feature Scaling</li> <li>After Feature Encoding</li> </ul> </li> <li> <p>Header &amp; Overview     GIF and a markdown introduction help the user understand what the EDA panel does.</p> </li> <li> <p>Visual Grid     Users are presented with a categorized set of plotting options:</p> <ul> <li>Basic Plots</li> <li>Advanced Plots</li> <li>Specialized Plots</li> <li>Geospatial Visualizations</li> </ul> </li> <li> <p>Click to Generate     On clicking a plot type:</p> <ul> <li>The corresponding visualization function is invoked.</li> <li>The selected plot appears with a title and a back button.</li> </ul> </li> </ol>"},{"location":"03_exploratory_data_analysis/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Data Source Selector Allows switching between raw and processed versions of the dataset. Plot Grid Shows image previews and labels of 15+ supported plots. One-click Plotting Clicking a plot button immediately renders the visual. Plot Functions Powered by modular functions like <code>plot_histogram</code>, <code>plot_boxplot</code>, etc. Back Navigation Users can return to the grid easily via a back button."},{"location":"03_exploratory_data_analysis/#visualization-types-supported","title":"\ud83d\udcca Visualization Types Supported","text":""},{"location":"03_exploratory_data_analysis/#basic-plots","title":"\ud83d\udd39 Basic Plots","text":"Plot Type Purpose / Use Case Box Plot Shows the spread and skewness of data via quartiles and outliers. \u2705 Best for comparing feature distributions, spotting outliers. Histogram Displays frequency distribution of numeric values. \u2705 Helps detect skewness, modality, and data concentration. Scatter Plot Visualizes relationships between two continuous variables. \u2705 Useful for detecting correlations and clusters. Bar Chart Compares quantities of categorical variables. \u2705 Ideal for viewing counts or aggregations across categories. Pie Chart Shows proportional breakdown of categorical variables. \u2705 Good for visualizing share/percentage composition. Line Plot Displays trends across time or ordered observations. \u2705 Best for time-series or sequential data analysis."},{"location":"03_exploratory_data_analysis/#advanced-plots","title":"\ud83d\udd38 Advanced Plots","text":"Plot Type Purpose / Use Case 2D Hist Contour Combines density-based histogram with contour lines. \u2705 Useful when you want to detect dense regions in bivariate data. Contour Plot Displays 3D surface on a 2D plane using contours. \u2705 Ideal for understanding gradient/response surfaces. Violin Plot Combines box plot and kernel density plot. \u2705 Great for understanding the distribution shape and symmetry. 3D Scatter Visualizes 3D relationships between 3 continuous variables. \u2705 Useful for dimensional analysis and observing clusters. 3D Line Connects points in 3D space. \u2705 Helpful for time-based sequences across three dimensions."},{"location":"03_exploratory_data_analysis/#specialized-plots","title":"\ud83c\udfaf Specialized Plots","text":"Plot Type Purpose / Use Case Polar Scatter Plots data on a circular axis (angle and radius). \u2705 Best for directional or cyclical data (e.g., wind direction, time). Polar Bar Like a bar chart in a circular layout. \u2705 Useful for periodic or circular metrics (e.g., sales across 12 months)."},{"location":"03_exploratory_data_analysis/#geospatial-visualizations","title":"\ud83c\udf0d Geospatial Visualizations","text":"Plot Type Purpose / Use Case Scatter Map Plots points on a geographical map. \u2705 Excellent for visualizing locations (e.g., store distribution, incident reports). Choropleth Map Colors geographic areas based on a variable. \u2705 Great for showing demographic density, income levels, or COVID spread. Bubble Map Uses bubbles to show values over geographical coordinates. \u2705 Perfect for showing magnitude across locations (e.g., sales, population)."},{"location":"03_exploratory_data_analysis/#ai-integration","title":"\ud83e\udd16 AI Integration","text":"<p>While this panel does not directly use GPT, it is fully compatible with previous and subsequent AI-assisted panels where generated insights complement these visualizations.</p>"},{"location":"03_exploratory_data_analysis/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Blog: How to choose the right data visualization</li> <li>Blog: A Complete Guide to Python Data Visualization</li> <li>Blog: Types of Plots: Visualization from Concept to Code</li> </ul>"},{"location":"04_impute_missing_values/","title":"04 \u2013 Impute Missing Values","text":""},{"location":"04_impute_missing_values/#ride-user-manual-panel-4-impute-missing-values","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 4: Impute Missing Values","text":""},{"location":"04_impute_missing_values/#purpose-of-the-panel","title":"\ud83e\udde0 Purpose of the Panel","text":"<p>This panel allows users to handle missing values in their dataset using nine distinct strategies ranging from simple deletion to statistical and ML-inspired methods. The goal is to maintain dataset integrity while preparing for modeling or analysis.</p> <p><code>Recommended Reading</code></p> <ul> <li>Kaggle Notebook: A Guide to Handling Missing values in Python</li> <li>Pandas Official Documentation: Work with Missing Data</li> <li>Blog: Top Techniques to Handle Missing Values Every Data Scientist Should Know</li> </ul>"},{"location":"04_impute_missing_values/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset     Automatically initializes <code>df_processed</code> from the uploaded dataset.</p> </li> <li> <p>Review Current Data     The current dataset (with missing values) is displayed.</p> </li> <li> <p>Missing Values Summary     A visual summary highlights all features with missing values.</p> </li> <li> <p>Imputation Settings</p> <ul> <li>Select a column with missing data.</li> <li>Choose an imputation method.</li> <li>If applicable, input a specific replacement value.</li> </ul> </li> <li> <p>Apply &amp; View Results</p> <ul> <li>Press the \u201cApply Imputation\u201d button.</li> <li>View/download the processed data.</li> </ul> </li> </ol>"},{"location":"04_impute_missing_values/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Column Selection Dropdown to choose a column with missing values. Imputation Method Picker Dropdown with 9 methods to handle missing values. Value Input (Conditional) User enters value when using \u201cReplace with Specific Value.\u201d Imputation Logic Execution Custom logic executed depending on the chosen method. Feedback &amp; Result Viewer Instant success/error message, optional data preview, and downloadable result."},{"location":"04_impute_missing_values/#imputation-methods-significance","title":"\ud83e\uddea Imputation Methods &amp; Significance","text":"Method Explanation When to Use 1. Drop Missing Values Removes all rows where the selected column has a missing value. \u2705 Simple but risky if data loss is significant. Use only when missing rows are few and ignorable. 2. Replace with Specific Value Replaces missing values with a fixed value entered by the user. \u2705 Good for categorical defaults or domain-specific values. Use when you have contextual knowledge (e.g., 0 = No Response). 3. Forward Fill (ffill) Fills each missing value with the last known value above it. \u2705 Useful for time-series or ordered data. Use when data has a logical time flow. 4. Backward Fill (bfill) Fills missing values with the next known value below it. \u2705 Similar to ffill but forward-looking. Use in reverse-time data or last-to-first ordering. 5. Distribution Sampling Randomly samples values from the column's distribution (normal approximation). \u2705 Keeps variability and prevents overfitting. Use for continuous, numeric columns with normal-like distributions. 6. Mean Imputation Fills missing values with the mean of the column. \u2705 Easy, but may reduce variance. Use with normally distributed, symmetric numeric data. 7. Median Imputation Fills with the median of the column. \u2705 Better than mean for skewed data. Use with skewed or outlier-heavy numeric features. 8. Nearest Neighbors Estimates missing values based on similarity to nearest rows (distance-based). \u2705 Sophisticated but computationally heavier. Use when strong similarity exists among rows. 9. Interpolation Fills values by interpolating between surrounding known values. \u2705 Natural fit for numeric, ordered data. Best for numeric sequences or time-series data."},{"location":"04_impute_missing_values/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Kaggle Notebook: A Guide to Handling Missing values in Python</li> <li>Pandas Official Documentation: Work with Missing Data</li> <li>Blog: Top Techniques to Handle Missing Values Every Data Scientist Should Know</li> </ul>"},{"location":"05_feature_encoding/","title":"05 \u2013 Feature Encoding","text":""},{"location":"05_feature_encoding/#ride-user-manual-panel-5-feature-encoding","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 5: Feature Encoding","text":""},{"location":"05_feature_encoding/#purpose-of-the-panel","title":"\ud83c\udfaf Purpose of the Panel","text":"<p>The Feature Encoding panel helps convert categorical variables into numerical form so they can be used in machine learning models. Users can choose between Label Encoding, One Hot Encoding, and Ordinal Encoding depending on the data's characteristics.</p> <p><code>Recommended Reading</code></p> <ul> <li>Blog: Feature Encoding</li> <li>Blog: All you need to know about encoding techniques!</li> </ul>"},{"location":"05_feature_encoding/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset     Option to use either:</p> <ul> <li>Initial DataFrame</li> <li>DataFrame after Missing Value Imputation</li> </ul> </li> <li> <p>Choose Columns &amp; Method</p> <ul> <li>Select one or more categorical columns.</li> <li>Pick an encoding method.</li> </ul> </li> <li> <p>Apply Encoding</p> <ul> <li>Transforms the selected columns using the chosen method.</li> <li>Shows:<ul> <li>Resulting encoded dataset</li> <li>Column structure comparison (before vs after)</li> </ul> </li> <li>Option to download the transformed dataset.</li> </ul> </li> </ol>"},{"location":"05_feature_encoding/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Data Source Selection Choose between raw or imputed data. Encoding Method Selector Label, One Hot, or Ordinal encoding. Multi-column Encoding Allows encoding multiple columns at once. Before/After Comparison View Side-by-side view of original vs new feature structure. Encoded Data Preview See the first few rows of the transformed dataset. Download Encoded Dataset Export results as CSV for later use."},{"location":"05_feature_encoding/#encoding-methods-when-to-use-them","title":"\ud83e\udde0 Encoding Methods &amp; When to Use Them","text":"Encoding Method Description Best Used For Example Label Encoding Assigns each unique category a number (0, 1, 2...). Ordinal categorical data <code>Low \u2192 0</code>, <code>Medium \u2192 1</code>, <code>High \u2192 2</code> One Hot Encoding Creates binary columns for each category (<code>0</code> or <code>1</code>). Nominal (unordered) data <code>Color \u2192 [is_red, is_blue, is_green]</code> Ordinal Encoding Similar to Label, but requires understanding of order. Ordinal with meaningful rank <code>Small \u2192 1</code>, <code>Medium \u2192 2</code>, <code>Large \u2192 3</code> <ul> <li>Label Encoding: What is label encoding? Application of label encoder in machine learning and deep learning models.</li> <li>One Hot Encoding: What Is One Hot Encoding and How to Implement It in Python</li> <li>Ordinal Encoding: Ordinal Encoding \u2014 A Brief Explanation</li> </ul>"},{"location":"05_feature_encoding/#why-encoding-matters","title":"\ud83d\udd0d Why Encoding Matters","text":"<p>Most machine learning algorithms require numeric inputs. Encoding ensures:</p> <ul> <li>Categorical features are interpreted correctly by models.</li> <li>No bias is introduced by incorrect ordinal assumptions.</li> <li>Models can capture class-related behavior from nominal features.</li> </ul>"},{"location":"05_feature_encoding/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Blog: Feature Encoding</li> <li>Blog: All you need to know about encoding techniques!</li> </ul>"},{"location":"06_feature_scaling_and_transformation/","title":"06 \u2013 Feature Scaling & Transformation","text":""},{"location":"06_feature_scaling_and_transformation/#ride-user-manual-panel-6-feature-scaling-transformation","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 6: Feature Scaling &amp; Transformation","text":""},{"location":"06_feature_scaling_and_transformation/#purpose-of-the-panel","title":"\ud83d\udcca Purpose of the Panel","text":"<p>This panel allows users to normalize, standardize, or transform features for better performance in machine learning models. Proper scaling and transformation:</p> <ul> <li>Makes algorithms converge faster.</li> <li>Prevents features with larger magnitudes from dominating the model.</li> <li>Handles skewness and non-normal distributions.</li> </ul> <p><code>Recommended Reading</code></p> <ul> <li>Blog: When to perform scaling</li> <li>Blog: About Feature Scaling and Normalization</li> <li>Blog: Feature Scaling: Engineering, Normalization, and Standardization</li> <li>Blog: Feature Transformation- Part of Feature Engineering</li> <li>Kaggle Notebook: All about Feature Transformation</li> </ul>"},{"location":"06_feature_scaling_and_transformation/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset     Choose from:</p> <ul> <li>Initial DataFrame</li> <li>After Missing Value Imputation</li> <li>After Feature Encoding</li> </ul> </li> <li> <p>Select Scaling or Transformation Method     Choose from 8 methods split into two categories:    </p> <ul> <li>Feature Scaling</li> <li>Feature Transformation</li> </ul> </li> <li> <p>Choose Features to Scale     Select one or more numeric columns.</p> </li> <li> <p>View Results </p> <ul> <li>Preview scaled data</li> <li>See summary stats before and after scaling</li> <li>Compare original vs transformed distributions</li> </ul> </li> <li> <p>Download Scaled Data     Download the transformed dataset for modeling.</p> </li> </ol>"},{"location":"06_feature_scaling_and_transformation/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Source Selector Choose between raw, imputed, or encoded datasets. Scaling Method Selector Includes both scaling and transformation strategies. Numeric Column Detection Uses utility to auto-select numeric features. Before/After Summary Side-by-side stats before and after scaling. Distribution Comparison Interactive histogram to compare original vs scaled distributions. Download Transformed Data Exports the result as a CSV."},{"location":"06_feature_scaling_and_transformation/#scaling-transformation-methods","title":"\ud83d\udd27 Scaling &amp; Transformation Methods","text":""},{"location":"06_feature_scaling_and_transformation/#feature-scaling","title":"\ud83d\udccf Feature Scaling","text":"Method Description Best For Min-Max Scaling Rescales values to [0, 1] range. When bounded input is required (e.g., image pixel values). Standardization (Z-score) Centers data with \u03bc=0 and \u03c3=1. When data needs normalization for gradient-based models. Robust Scaler Uses IQR (Q3 - Q1), ignores outliers. When outliers are present and shouldn't dominate scaling. Max AbsScaler Scales by max absolute value. When dealing with sparse data (e.g., TF-IDF). <ul> <li>Min-Max Scaling: How Min-Max Scaler Works</li> <li>Standardization(z-score): z-Score</li> <li>Robust Scaling: Robust Scaling: Why and How to Use It to Handle Outliers</li> <li>Max AbsScaler: Using Max Abs Scaler for feature scaling | Machine Learning</li> </ul>"},{"location":"06_feature_scaling_and_transformation/#feature-transformation","title":"\ud83d\udd04 Feature Transformation","text":"Method Description Best For Quantile Transformer Converts feature to a uniform distribution. When feature values are heavily skewed. Log Transformer Applies <code>log(1 + x)</code>. Right-skewed distributions (e.g., income, prices). Power Transformer (Box-Cox) Normalizes data using \u03bb parameter. Positive-only data with non-normal shape. Power Transformer (Yeo-Johnson) Modified Box-Cox, supports negatives. Mixed-sign numeric data needing normalization. <ul> <li>Quantile Transformer, Power Transformer and Log Transform: 5 Data Transformers to know from Scikit-Learn </li> </ul>"},{"location":"06_feature_scaling_and_transformation/#why-this-panel-matters","title":"\ud83e\udde0 Why This Panel Matters","text":"<ul> <li>Scaling ensures model convergence and fair weight distribution.</li> <li>Transformation can reduce skewness and make data more Gaussian, which is preferred by many statistical and ML models.</li> </ul>"},{"location":"06_feature_scaling_and_transformation/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Blog: When to perform scaling</li> <li>Blog: About Feature Scaling and Normalization</li> <li>Blog: Feature Scaling: Engineering, Normalization, and Standardization</li> <li>Blog: Feature Transformation- Part of Feature Engineering</li> <li>Kaggle Notebook: All about Feature Transformation</li> </ul>"},{"location":"07_distribution_diagnostics/","title":"07 \u2013 Distribution Diagnostics","text":""},{"location":"07_distribution_diagnostics/#ride-user-manual-panel-7-statistical-data-exploration","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 7: Statistical Data Exploration","text":""},{"location":"07_distribution_diagnostics/#purpose-of-the-panel","title":"\ud83d\udcca Purpose of the Panel","text":"<p>The Distribution Diagnostics Panel allows users to: - Understand data shape via skewness and kurtosis - Test for normality with Q-Q plots and statistical tests - Detect outliers using the IQR method</p> <p>This is crucial for identifying data anomalies, choosing suitable transformations, and selecting proper machine learning models.</p> <p><code>Recommended Reading</code></p> <ul> <li>Blog: The Q-Q Plot: What It Means and How to Interpret It</li> <li>Blog: Understanding QQ Plots</li> <li>Blog: Kurtosis</li> <li>Blog: Measures of Kurtosis and Skewness</li> <li>Blog: Right Skewed vs. Left Skewed Distribution</li> <li>Blog: The Complete Guide to Skewness and Kurtosis</li> <li>Blog: What Is an Outlier?</li> <li>Blog: What are outliers in the data?</li> <li>Blog: What Are Outliers in Data Sciences?</li> </ul>"},{"location":"07_distribution_diagnostics/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset     Choose from:</p> <ul> <li>Initial DataFrame</li> <li>After Missing Value Imputation</li> <li>After Feature Encoding</li> <li>After Feature Scaling</li> </ul> </li> <li> <p>Navigate the Tabs:</p> <ul> <li>\ud83d\udcca Distribution &amp; Q-Q Plots: Visualize histograms + Q-Q plots, run normality tests.</li> <li>\ud83c\udfd4\ufe0f Kurtosis: Check how \u201cpeaked\u201d or \u201cflat\u201d distributions are.</li> <li>\u2197\ufe0f Skewness: Explore asymmetry in distributions.</li> <li>\ud83d\udd0d Outliers: Detect extreme values using IQR logic.</li> </ul> </li> <li> <p>Interactive Visuals:</p> <ul> <li>Select numeric features.</li> <li>Compare histograms and Q-Q plots.</li> <li>Get metric summaries and AI insights.</li> </ul> </li> </ol>"},{"location":"07_distribution_diagnostics/#features-breakdown","title":"\ud83d\udcbb Features Breakdown","text":"Feature Description Data Source Selection Choose which version of dataset to analyze. Distribution Analysis Histogram + KDE + Q-Q Plot. Statistical Tests Shapiro-Wilk, Kolmogorov-Smirnov, Anderson-Darling. Skewness Panel Visual and numeric skewness for all columns. Kurtosis Panel Measures tailedness; interprets platykurtic vs leptokurtic. Outlier Detection Uses IQR method; gives upper/lower bounds, values, and percentage. AI Explanation GPT-generated summaries for kurtosis and skewness."},{"location":"07_distribution_diagnostics/#what-each-technique-tells-you","title":"\ud83d\udd0d What Each Technique Tells You","text":""},{"location":"07_distribution_diagnostics/#skewness","title":"\ud83d\udfe9 Skewness","text":"Type Interpretation When It Matters = 0 Symmetric distribution (Normal) Good baseline for modeling &gt; 0 Right-skewed (long right tail) Log transformation may help &lt; 0 Left-skewed (long left tail) Square-root or Box-Cox might help"},{"location":"07_distribution_diagnostics/#kurtosis","title":"\ud83d\udfea Kurtosis","text":"Type Interpretation When It Matters \u2248 0 Normal-tailed (mesokurtic) Safe for most parametric tests &gt; 0 Heavy-tailed (leptokurtic) Higher chance of outliers &lt; 0 Light-tailed (platykurtic) More uniform, less prone to extremes"},{"location":"07_distribution_diagnostics/#q-q-plot","title":"\ud83d\udfe5 Q-Q Plot","text":"<ul> <li>Compares quantiles of sample distribution to a normal distribution.</li> <li>S-shaped curve: Skewed data.</li> <li>Straight line: Normal distribution.</li> </ul>"},{"location":"07_distribution_diagnostics/#statistical-tests-for-normality","title":"\ud83d\udfe8 Statistical Tests for Normality","text":"Test Description When It\u2019s Used Shapiro-Wilk Most powerful for n &lt; 5000 Small to medium datasets Kolmogorov-Smirnov Compares empirical vs normal distribution (uses \u03bc and \u03c3 from data) For larger datasets Anderson-Darling Strong test across all sizes Offers critical value comparison <ul> <li>Shapiro-Wilk Test: Wikipedia</li> <li>Shapiro-Wilk Test: An Introduction to the Shapiro-Wilk Test for Normality</li> <li>Kolmogorov-Smirnov: Wikipedia</li> <li>Kolmogorov-Smirnov: Interpreting results: Kolmogorov-Smirnov test</li> <li>Anderson-Darling Test: Wikipedia</li> <li>Anderson-Darling Test: A Complete Guide to the Anderson-Darling Normality Test</li> </ul>"},{"location":"07_distribution_diagnostics/#outlier-detection-iqr-method","title":"\ud83e\uddee Outlier Detection (IQR Method)","text":"<ul> <li>IQR = Q3 - Q1</li> <li>Outliers:<ul> <li>Below: Q1 \u2212 1.5 \u00d7 IQR</li> <li>Above: Q3 + 1.5 \u00d7 IQR</li> </ul> </li> <li>Users can tune k (IQR multiplier) to make detection more or less sensitive.</li> </ul>"},{"location":"07_distribution_diagnostics/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Blog: The Q-Q Plot: What It Means and How to Interpret It</li> <li>Blog: Understanding QQ Plots</li> <li>Blog: Kurtosis</li> <li>Blog: Measures of Kurtosis and Skewness</li> <li>Blog: Right Skewed vs. Left Skewed Distribution</li> <li>Blog: The Complete Guide to Skewness and Kurtosis</li> <li>Blog: What Is an Outlier?</li> <li>Blog: What are outliers in the data?</li> <li>Blog: What Are Outliers in Data Sciences?</li> </ul>"},{"location":"08_statistical_tests/","title":"08 \u2013 Statistical Tests","text":""},{"location":"08_statistical_tests/#ride-user-manual-panel-8-statistical-tests","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 8: Statistical Tests","text":""},{"location":"08_statistical_tests/#purpose-of-the-panel","title":"\ud83d\udcca Purpose of the Panel","text":"<p>The Statistical Tests panel allows users to run hypothesis tests on their data to determine:</p> <ul> <li>Differences between groups</li> <li>Associations between categorical variables</li> <li>Normality of distributions</li> </ul> <p>Users can choose from 6 popular tests depending on data type, assumptions, and goals.</p> <p><code>Recommended Reading</code></p> <ul> <li>Blog: Two-Sample T-Test</li> <li>Blog: The Two-Sample t-Test</li> <li>Blog: Two Sample t-test: Definition, Formula, and Example</li> <li>Blog: Analysis of Variance (ANOVA) Guide with Examples</li> <li>Blog: Analysis of Variance Tutorial</li> <li>Blog: Chi-Square test</li> <li>Blog: Chi-Square (\u03a7\u00b2) Tests | Types, Formula &amp; Examples</li> <li>Blog: Chi-Square Test of Independence | Formula, Guide &amp; Examples</li> <li>Blog: Mann-Whitney U-Test</li> <li>Blog: The Mann-Whitney U Test</li> <li>Blog: How to Conduct a Wilcoxon Signed Rank Test</li> <li>Blog: Wilcoxon signed-rank test</li> <li>Blog: Kruskal-Wallis-Test</li> </ul>"},{"location":"08_statistical_tests/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset     Choose from:</p> <ul> <li>Initial DataFrame</li> <li>Imputed, Encoded, or Scaled DataFrame</li> </ul> </li> <li> <p>Choose a Statistical Test     Options include:</p> <ul> <li>2-Sample T-Test</li> <li>ANOVA</li> <li>Chi-Square Test</li> <li>Mann-Whitney U Test</li> <li>Wilcoxon Signed-Rank Test</li> <li>Kruskal-Wallis Test</li> </ul> </li> <li> <p>Select Group &amp; Value Columns     Based on the test chosen, select a categorical column (for grouping) and a numerical column (for values).</p> </li> <li> <p>Visualize Distributions (Optional)     Choose to view histograms, box plots, or group distributions.</p> </li> <li> <p>Run the Test     Get test statistics, p-values, interpretation, and AI-generated summaries if OpenAI API is enabled.</p> </li> </ol>"},{"location":"08_statistical_tests/#statistical-test-explanations-with-formulas-use-cases","title":"\ud83e\uddea Statistical Test Explanations with Formulas &amp; Use Cases","text":""},{"location":"08_statistical_tests/#1-2-sample-t-test","title":"1. 2-Sample T-Test","text":"<ul> <li>Purpose: Compares means of two independent groups.</li> <li>Assumptions: Normal distribution, equal variances.<ul> <li>Formula \\(t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\)</li> <li>\\(\\bar{x}_1\\) and \\(\\bar{x}_2\\) are the sample means</li> <li>\\(s_1^2\\) and \\(s_2^2\\) are the sample variances</li> <li>\\(n_1\\) and \\(n_2\\) are the sample sizes</li> </ul> </li> <li> <p>Example: Compare exam scores between two sections of students.</p> </li> <li> <p>Two-Sample T-Test</p> </li> <li>The Two-Sample t-Test</li> <li>Two Sample t-test: Definition, Formula, and Example</li> </ul>"},{"location":"08_statistical_tests/#2-anova-analysis-of-variance","title":"2. ANOVA (Analysis of Variance)","text":"<ul> <li>Purpose: Compares means of 3 or more independent groups.</li> <li>Assumptions: Normal distribution, equal variances.</li> <li>Formula:<ul> <li> \\[F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}} = \\frac{MS_{between}}{MS_{within}}\\] </li> <li>The \\(F\\)-statistic compares \\(MS_{between}\\) to \\(MS_{within}\\)</li> <li>\\(MS_{between}\\) represents the between-group variance</li> <li>\\(MS_{within}\\) represents the within-group variance</li> </ul> </li> <li> <p>Example: Compare customer satisfaction across 4 product lines.</p> </li> <li> <p>Analysis of Variance (ANOVA) Guide with Examples</p> </li> <li>Analysis of Variance Tutorial</li> </ul>"},{"location":"08_statistical_tests/#3-chi-square-test","title":"3. Chi-Square Test","text":"<ul> <li>Purpose: Tests for independence between two categorical variables.</li> <li>Assumptions: Expected frequencies \u2265 5.<ul> <li>Formula: \\(\\chi^2 = \\sum \\frac{(O - E)^2}{E}\\)</li> </ul> </li> <li>where \\(O\\) is observed frequency, \\(E\\) is expected frequency.</li> <li> <p>Example: Test if gender and preferred drink are related.</p> </li> <li> <p>Chi-Square test</p> </li> <li>Chi-Square (\u03a7\u00b2) Tests | Types, Formula &amp; Examples</li> <li>Chi-Square Test of Independence | Formula, Guide &amp; Examples</li> </ul>"},{"location":"08_statistical_tests/#4-mann-whitney-u-test","title":"4. Mann-Whitney U Test","text":"<ul> <li>Purpose: Non-parametric alternative to T-test (for non-normal data).</li> <li>Assumptions: Independent samples, ordinal/numeric values.</li> <li>Formula: \\(U = n_1 n_2 + \\frac{n_1(n_1+1)}{2} - R_1\\) <ul> <li>where \\(R_1\\) is the sum of ranks in group 1.</li> </ul> </li> <li> <p>Example: Compare ratings of two movies.</p> </li> <li> <p>Mann-Whitney U-Test</p> </li> <li>The Mann-Whitney U Test</li> </ul>"},{"location":"08_statistical_tests/#5-wilcoxon-signed-rank-test","title":"5. Wilcoxon Signed-Rank Test","text":"<ul> <li>Purpose: Non-parametric test for paired data.</li> <li>Assumptions: Symmetric distribution of differences.</li> <li>Formula Wilcoxon Signed-Rank Test \\(W = \\sum_{i=1}^{n} [sgn(x_{2,i} - x_{1,i}) \\cdot R_i]\\)<ul> <li>where \\(R_i\\) is the rank of the absolute difference, and \\(sgn()\\) is the sign function.</li> </ul> </li> <li> <p>Example: Compare before/after treatment scores for same patients.</p> </li> <li> <p>How to Conduct a Wilcoxon Signed Rank Test</p> </li> <li>Wilcoxon signed-rank test</li> </ul>"},{"location":"08_statistical_tests/#6-kruskal-wallis-h-test","title":"6. Kruskal-Wallis H Test","text":"<ul> <li>Purpose: Non-parametric ANOVA (3+ groups, not normally distributed).</li> <li>Kruskal-Wallis H Test</li> <li>Formula:</li> <li> \\[H = \\frac{12}{n(n+1)} \\sum \\frac{R_i^2}{n_i} - 3(n+1)\\] <ul> <li>where \\(R_i\\) is the sum of ranks in group \\(i\\), \\(n_i\\) is the sample size of group \\(i\\), and \\(n\\) is the total sample size.</li> </ul> </li> <li> <p>Example: Compare time spent on app across multiple age groups.</p> </li> <li> <p>Kruskal-Wallis-Test</p> </li> </ul>"},{"location":"08_statistical_tests/#summary-table","title":"\ud83d\udd0d Summary Table","text":"Test Parametric? Groups Data Type Use When T-Test Yes 2 Numeric Comparing two groups (normal) ANOVA Yes \u22653 Numeric Comparing \u22653 groups (normal) Chi-Square No \u22652 Categorical Check relationships Mann-Whitney U No 2 Numeric (Ordinal) Two groups, not normal Wilcoxon No Paired Numeric (Ordinal) Paired samples, not normal Kruskal-Wallis No \u22653 Numeric (Ordinal) \u22653 groups, not normal"},{"location":"08_statistical_tests/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Blog: Two-Sample T-Test</li> <li>Blog: The Two-Sample t-Test</li> <li>Blog: Two Sample t-test: Definition, Formula, and Example</li> <li>Blog: Analysis of Variance (ANOVA) Guide with Examples</li> <li>Blog: Analysis of Variance Tutorial</li> <li>Blog: Chi-Square test</li> <li>Blog: Chi-Square (\u03a7\u00b2) Tests | Types, Formula &amp; Examples</li> <li>Blog: Chi-Square Test of Independence | Formula, Guide &amp; Examples</li> <li>Blog: Mann-Whitney U-Test</li> <li>Blog: The Mann-Whitney U Test</li> <li>Blog: How to Conduct a Wilcoxon Signed Rank Test</li> <li>Blog: Wilcoxon signed-rank test</li> <li>Blog: Kruskal-Wallis-Test</li> </ul>"},{"location":"09_automl/","title":"09 \u2013 AutoML","text":""},{"location":"09_automl/#ride-user-manual-panel-9-automl-machine-learning-explorer","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 9: \ud83e\udd16 AutoML (Machine Learning Explorer)","text":""},{"location":"09_automl/#purpose-of-the-panel","title":"\ud83d\ude80 Purpose of the Panel","text":"<p>The AutoML Panel helps users perform automated machine learning (AutoML) tasks for: - Regression - Classification - Clustering  </p>"},{"location":"09_automl/#without-writing-a-single-line-of-code-users-can","title":"Without writing a single line of code, users can:","text":"<ul> <li>Select a dataset</li> <li>Pick features and a target</li> <li>Choose between step-by-step or built-in preprocessing</li> <li>Run advanced models</li> <li>Explore evaluation metrics for the models</li> <li>Export predictions</li> </ul> <p>It integrates a powerful backend to run model pipelines, manage parallel execution, and rank models by performance.</p>"},{"location":"09_automl/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li>Upload Dataset &amp; Choose Variant Choose from Initial, Imputed, Scaled, or Encoded DataFrames.</li> <li> <p>Select Task</p> <ul> <li>Regression Analysis</li> <li>Classification Analysis</li> <li>Clustering Analysis</li> <li>(Time Series \u2013 coming soon)</li> </ul> </li> <li> <p>Choose Columns</p> <ul> <li>Select features and a target variable.</li> <li>Handles missing targets intelligently.</li> </ul> </li> <li> <p>Preprocessing Mode</p> <ul> <li>Choose between:<ul> <li>\u2699\ufe0f Step-by-step preprocessing via previous panels</li> <li>\ud83d\udd04 One-click automatic pipeline (<code>eval.py</code> handles everything inside the model)</li> </ul> </li> </ul> </li> <li> <p>Run Analysis</p> <ul> <li>Press a button to start training.</li> <li>Behind the scenes, dozens of models are evaluated.</li> </ul> </li> <li> <p>Results</p> <ul> <li>View top-performing models</li> <li>See metrics like R\u00b2, Adjusted R\u00b2, RMSE, Accuracy, F1, ROC-AUC</li> <li>Download results and predictions</li> </ul> </li> <li> <p>Clustering</p> <ul> <li>Choose standard or PCA-based clustering</li> <li>Visualize clusters in 2D space</li> <li>Download labeled datasets</li> </ul> </li> </ol>"},{"location":"09_automl/#how-it-works-internally-evalpy","title":"\ud83e\udd16 How It Works Internally \u2013 <code>eval.py</code>","text":"<ul> <li>Model Registry: Dynamically filters usable models based on dataset size.</li> <li>Preprocessing:<ul> <li>Numeric \u2192 Imputed with mean, scaled with <code>StandardScaler</code></li> <li>Low-cardinality categorical \u2192 OneHotEncoded</li> <li>High-cardinality categorical \u2192 OrdinalEncoded</li> </ul> </li> <li>Parallel Execution: Uses <code>ProcessPoolExecutor</code> to run models in parallel.</li> <li>Memory Management: Skips memory-intensive models for large datasets.</li> <li>Metric Calculation:<ul> <li>Classification: Accuracy, Balanced Accuracy, F1 Score, ROC-AUC</li> <li>Regression: R\u00b2, Adjusted R\u00b2, RMSE</li> </ul> </li> <li>Model Filtering: Automatically excludes unsuitable models for your task.</li> </ul>"},{"location":"09_automl/#key-metrics-explained","title":"\ud83e\uddea Key Metrics Explained","text":""},{"location":"09_automl/#regression","title":"\ud83d\udd22 Regression","text":"Metric Formula Description R\u00b2 \\(R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\\) Measures the proportion of variance explained by the model. Values range from 0 to 1, with higher values indicating better fit. An R\u00b2 of 0.7 means 70% of the outcome variation is explained by the model. Adjusted R\u00b2 \\(1 - \\frac{(1 - R^2)(n - 1)}{n - p - 1}\\) Modified version of R\u00b2 that penalizes for adding unnecessary predictors. Prevents overfitting by accounting for model complexity. Always lower than R\u00b2, and may decrease when irrelevant features are added. RMSE \\(\\sqrt{\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2}\\) Root Mean Square Error measures the average prediction error in the same units as the dependent variable. Lower values indicate better fit. Useful for understanding practical significance of model errors and comparing models with the same target variable."},{"location":"09_automl/#classification","title":"\u2705 Classification","text":"Metric Formula Description Accuracy \\(\\frac{TP + TN}{TP + TN + FP + FN}\\) Measures the proportion of correctly classified instances (both positive and negative). Simple but potentially misleading with imbalanced datasets. A 99% accuracy could mean simply predicting the majority class in a dataset with 99:1 class ratio. Balanced Accuracy \\(\\frac{1}{2} \\left( \\frac{TP}{TP + FN} + \\frac{TN}{TN + FP} \\right)\\) Average of sensitivity and specificity, giving equal weight to both classes regardless of their size. Better for imbalanced datasets as it prevents models from achieving high scores by simply predicting the majority class. F1 Score \\(2 \\cdot \\frac{precision \\cdot recall}{precision + recall} = \\frac{2TP}{2TP + FP + FN}\\) Harmonic mean of precision and recall, balancing both false positives and false negatives. Particularly useful when class imbalance exists and both false positives and negatives have significant consequences. Values range from 0 to 1. ROC-AUC Area under the ROC curve plotting True Positive Rate vs False Positive Rate Measures model's ability to discriminate between classes across all possible classification thresholds. A value of 0.5 indicates random guessing, 1.0 is perfect classification. Less affected by class imbalance than accuracy. Shows model's ranking ability rather than its calibration."},{"location":"09_automl/#clustering-metrics","title":"\ud83d\udd00 Clustering Metrics","text":"Metric Description Inertia Sum of squared distances within clusters (used in elbow method) Silhouette Score Measures separation between clusters (ranges from -1 to 1) PCA Explained Variance Shows how much variance each principal component retains"},{"location":"10_chat_with_data/","title":"10 \u2013 Chat with Data","text":""},{"location":"10_chat_with_data/#ride-user-manual-panel-10-chat-with-data-openai-hugging-face","title":"\ud83d\udcd8 RIDE User Manual \u2013 Panel 10: \ud83e\udde0 Chat with Data (OpenAI + Hugging Face)","text":""},{"location":"10_chat_with_data/#purpose-of-the-panel","title":"\ud83c\udfaf Purpose of the Panel","text":"<p>The Chat with Data panel empowers users to explore, analyze, and visualize their dataset through natural language prompts. It integrates with:</p> <ul> <li>OpenAI GPT Models (e.g., <code>gpt-4o</code>, <code>gpt-4o-mini</code>)</li> <li>Hugging Face Transformers (e.g., Mixtral, Mistral, Gemma, Falcon)</li> </ul> <p>Users can ask questions about: - Dataset structure - Summary statistics - Missing values - Trends, correlations - Visualizations (bar, line, scatter, heatmaps) - Python code generation for transformations or EDA</p>"},{"location":"10_chat_with_data/#user-workflow","title":"\ud83e\udded User Workflow","text":"<ol> <li> <p>Upload Dataset</p> <ul> <li>Upload CSV or Excel file.</li> <li>The dataset is automatically read and shown in a preview.</li> </ul> </li> <li> <p>Choose Model Provider</p> <ul> <li>\ud83e\udde0 OpenAI (requires OpenAI API key)</li> <li>\ud83e\udd17 Hugging Face (requires Hugging Face API token)</li> </ul> </li> <li> <p>Select a DataFrame</p> <ul> <li>Choose from initial, encoded, imputed, or scaled versions.</li> </ul> </li> <li> <p>Ask Questions</p> <ul> <li>Examples:<ul> <li>\u201cWhich column has the most missing values?\u201d</li> <li>\u201cPlot a bar chart of product categories.\u201d</li> <li>\u201cHow is age correlated with income?\u201d</li> </ul> </li> </ul> </li> <li> <p>Receive Answers</p> <ul> <li>Get responses in plain English.</li> <li>Includes Python code blocks if applicable.</li> <li>Auto-executed plots rendered inline.</li> </ul> </li> <li> <p>Track Execution</p> <ul> <li>Track query response times and performance metrics.</li> </ul> </li> </ol>"},{"location":"10_chat_with_data/#how-it-works","title":"\ud83e\udd16 How It Works","text":""},{"location":"10_chat_with_data/#openai-mode","title":"\ud83d\udd10 OpenAI Mode","text":"<ul> <li>Integrates with <code>openai.ChatCompletion</code>.</li> <li>Adds security filters to reject suspicious code (e.g., <code>eval()</code>, <code>subprocess</code>).</li> <li>Uses <code>safe_execute_code()</code> to interpret and safely execute Python code blocks.</li> <li>Tracks execution time and logs user queries.</li> <li>Caches formatting using <code>st.cache_data</code>.</li> </ul>"},{"location":"10_chat_with_data/#hugging-face-mode","title":"\ud83e\udd17 Hugging Face Mode","text":"<ul> <li>Uses <code>InferenceClient</code> from <code>huggingface_hub</code>.</li> <li>Formats prompts using <code>Mixtral</code>-style <code>[INST]</code> tokens.</li> <li>Directly queries LLMs with the full DataFrame context.</li> <li>Parses responses, extracts Python code blocks and executes them for visualizations.</li> </ul>"},{"location":"10_chat_with_data/#ai-safety-and-security","title":"\ud83e\udde0 AI Safety and Security","text":"Safety Feature Description Suspicious Pattern Detection Blocks unsafe queries (e.g., <code>drop table</code>, <code>open()</code>) Resource Limit Guarding Automatically samples large datasets Timeout Mechanism Halts long-running code after 30 seconds Restricted Libraries Only pandas, numpy, matplotlib, seaborn permitted"}]}